version: 2.1

orbs:
  singularity: singularity/singularity@1.0.10
  codecov: codecov/codecov@1.1.5

jobs:

  test-python-install:
    parameters:
      version:
        type: string
        default: latest
    docker:
      - image: circleci/python:<< parameters.version >>
    steps:
      - checkout
      - run:
          name: "Test Install Twine and PyBIDS"
          command: |
            python --version
            pip3 install twine
      - run:
          name: "Smoke Test Install Twine"
          command: |
            python --version
            twine upload -h
      - run:
          name: "Test Wheel Build for setup.py"
          command: |
            python3 setup.py sdist bdist_wheel
      - run:
          name: "Test Install for setup.py"
          command: |
            pip install .
      - run:
          name: "Smoke Test Install for setup.py"
          command: |
            python --version
            pip3 install cmp

  build_docker:
    environment:
      TZ: "/usr/share/zoneinfo/Europe/Zurich"
      SCRATCH: "/scratch"
    docker:
      - image: docker:19.03.1-git
    working_directory: tmp/src/connectomemapper3
    steps:
      - run:
          name: Install parallel gzip and python2
          command: |
            apk add --no-cache pigz python2
      - restore_cache:
          keys:
            - docker-{{ .Branch }}-{{ epoch }}
            - docker-{{ .Branch }}-
            - docker-master-
            - docker-
          paths:
            - /tmp/cache/docker.tar.gz
      - checkout
      - setup_remote_docker:
          docker_layer_caching: false
      - run:
          name: Load Docker image layer cache
          no_output_timeout: 30m
          command: |
            docker info
            set +o pipefail
            if [ -f /tmp/cache/docker.tar.gz ]; then
              pigz -d --stdout /tmp/cache/docker.tar.gz | docker load
              docker images
            fi
      - run:
          name: Build Docker image
          no_output_timeout: 120m
          command: |
            # Get version, update files.
            python --version
            THISVERSION=$( python get_version.py )
            echo "THISVERSION : ${THISVERSION}"
            echo "CIRCLE_TAG : ${CIRCLE_TAG}"
            if [[ ${THISVERSION:0:1} == "0" ]] ; then
              echo "WARNING: latest git tag could not be found"
              echo "Please, make sure you fetch all tags from upstream with"
              echo "the command ``git fetch --tags --verbose`` and push"
              echo "them to your fork with ``git push origin --tags``"
            fi
            # Build CMP BIDS App docker image
            ls -la .
            e=1 && for i in {1..5}; do
              docker build --cache-from sebastientourbier/connectomemapper3 --rm=true --build-arg BUILD_DATE=`date -u +"%Y-%m-%dT%H:%M:%SZ"` --build-arg VCS_REF=`git rev-parse --short HEAD` --build-arg VERSION="${CIRCLE_TAG:-$THISVERSION}" -t sebastientourbier/connectomemapper3 . \
              && e=0 && break || sleep 15
            done && [ "$e" -eq "0" ]
      - run:
          name: Prune Docker cache (temporary)
          command: docker system prune -f
      - run:
          name: Prune Docker volume (temporary)
          command: docker volume prune --force
      - run:
          name: Display storage information
          command: df -h
      # - run:
      #     name: Keep only connectomemapper docker image
      #     command: |
      #       docker rmi $(docker images | grep connectomemapper-ubuntu16.04 | tr -s ' ' | cut -d ' ' -f 3)
      - run:
          name: Save Docker Image
          no_output_timeout: 40m
          command: |
            # Get version, update files.
            THISVERSION=$( python get_version.py )
            mkdir -p /tmp/cache
            docker save sebastientourbier/connectomemapper3 \
            | pigz -8 -p 3 > /tmp/cache/docker.tar.gz
      - persist_to_workspace:
          root: /tmp
          paths:
            - cache/docker.tar.gz
            - src/connectomemapper3

  build_singularity:
    machine:
      # Ubuntu 16.04, docker 18.09.3, docker-compose 1.23.1
      image: ubuntu-1604:201903-01
    working_directory: /tmp/src/connectomemapper3
    steps:
      - checkout:
          path: /home/circleci/src/connectomemapper3
      - run:
          name: "Check whether build_singularity job should be skipped"
          command: |
            cd /home/circleci/src/connectomemapper3
            if [[ "$( git log --format=oneline -n 1 $CIRCLE_SHA1 | grep -i -E '\[skip[ _]?build_singularity]' )" != "" ]]; then
              echo "Skipping singularity build step"
              circleci step halt
            fi
      - attach_workspace:
          at: /tmp
      - run:
          name: "Starting local registry"
          command: docker run -d -p 5000:5000 --restart=always --name registry registry:2
      - run:
          name: "Load Docker image layer cache"
          no_output_timeout: 30m
          command: |
            docker info
            set +o pipefail
            if [ -f /tmp/cache/docker.tar.gz ]; then
              wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
              sudo apt-get update && sudo apt-get -y install pigz
              pigz -d --stdout /tmp/cache/docker.tar.gz | docker load
              docker images
              sudo rm /tmp/cache/docker.tar.gz
            fi
      - singularity/install-go:
          go-version: '1.13'
      - singularity/debian-install-3:
          singularity-version: 3.7.3
      - run:
          name: "Set SINGULARITY TMP and CACHEDIR to prevent overflowing the /tmp folder"
          command: |
            mkdir -p ~/.singularity/tmp
            export SINGULARITY_LOCALCACHEDIR=~/.singularity/tmp
            export SINGULARITY_CACHEDIR=~/.singularity/tmp
            export SINGULARITY_TMPDIR=~/.singularity/tmp
            export TMPDIR=~/.singularity/tmp
            export SINGULARITY_DISABLE_CACHE=true
            export
      - run:
          name: "Display storage information"
          command: |
            du -xm ~/ | sort -rn > ~/usage.txt
            echo "/home directory:"
            du -sh ~/
            echo "/tmp directory:"
            du -sh /tmp
      - run:
          name: "Display storage information ALL"
          command: |
            df -h
      - run:
          name: "Display storage information (df -h)"
          command: |
            echo "/home directory:"
            df -h ~/
            echo "/tmp directory:"
            df -h /tmp
      - run:
          name: "Building Singularity image from Docker image"
          command: |
            docker tag sebastientourbier/connectomemapper3 localhost:5000/sebastientourbier/connectomemapper3:latest
            docker push localhost:5000/sebastientourbier/connectomemapper3:latest
            docker images -a | grep "sebastientourbier/connectomemapper3"
            SINGULARITY_NOHTTPS=1 \
            SINGULARITY_LOCALCACHEDIR=~/.singularity/tmp \
            SINGULARITY_CACHEDIR=~/.singularity/tmp SINGULARITY_TMPDIR=~/.singularity/tmp \
            TMPDIR=~/.singularity/tmp SINGULARITY_DISABLE_CACHE=true \
            singularity --debug -v build /tmp/cache/connectomemapper3.simg docker://localhost:5000/sebastientourbier/connectomemapper3:latest
          no_output_timeout: 5h
      - run:
          name: Display storage information
          command: df -h
      - persist_to_workspace:
          root: /tmp
          paths:
            - cache/connectomemapper3.simg
      - store_artifacts:
          path: /tmp/cache/connectomemapper3.simg
      - store_artifacts:
          path: ~/usage.txt

  get_data:
    machine:
      # Ubuntu 16.04, docker 18.09.3, docker-compose 1.23.1
      image: ubuntu-1604:201903-01
    working_directory: /home/circleci/data
    steps:
      - run:
          name: Get test data from ds-sample
          command: |
            mkdir -p /tmp/data
            wget --retry-connrefused --waitretry=5 --read-timeout=20 --timeout=15 -t 0 -v \
              -O ds-sample.tar.gz "https://zenodo.org/record/3712762/files/ds-sample.tar.gz?download=1"
            tar xvzf ds-sample.tar.gz -C /tmp/data/
            echo "Dataset ds-sample has been successfully downloaded"
      - run:
          name: Get FreeSurfer derivatives for ds-sample
          command: |
            mkdir -p /tmp/data/ds-sample/derivatives
            wget --retry-connrefused --waitretry=5 --read-timeout=20 --timeout=15 -t 0 -v \
              -O freesurfer.tar.gz "https://zenodo.org/record/3712762/files/freesurfer.tar.gz?download=1"
            tar xvzf freesurfer.tar.gz -C /tmp/data/ds-sample/derivatives
            echo "FreeSurfer derivatives of ds-sample  have been successfully downloaded"
      - run:
          name: Store FreeSurfer license file
          command: |
            mkdir -p /tmp/data/ds-sample/code
            cd /tmp/data/ds-sample/code
            echo `echo c2ViYXN0aWVuLnRvdXJiaWVyMUBnbWFpbC5jb20KMzAwNzYKICpDYUpVZ0VMQlJEYkEKIEZTMkkyWDNwNkpicWcK== | base64 -di` > /tmp/data/ds-sample/code/license.txt
            cat /tmp/data/ds-sample/code/license.txt
      - persist_to_workspace:
          root: /tmp
          paths:
            - data
      - save_cache:
         key: data-{{ epoch }}
         paths:
            - /tmp/data

  test_docker_dsi_mrtrix:
    machine:
      # Ubuntu 16.04, docker 18.09.3, docker-compose 1.23.1
      image: ubuntu-1604:201903-01

    working_directory: /tmp/data
    environment:
      - FS_LICENSE: /tmp/data/${CIRCLE_JOB}/ds-sample/code/license.txt
    steps:
      - checkout:
          path: /home/circleci/src/connectomemapper3
      - run:
          name: Check whether test_docker_dsi_mrtrix should be skipped
          command: |
            cd /home/circleci/src/connectomemapper3
            if [[ "$( git log --format=oneline -n 1 $CIRCLE_SHA1 | grep -i -E '\[skip[ _]?test_docker_dsi_mrtrix\]' )" != "" ]]; then
              echo "Skipping test_docker_dsi_mrtrix job"
              circleci step halt
            fi
      - attach_workspace:
          at: /tmp
      - run:
          name: Load Docker image layer cache
          no_output_timeout: 30m
          command: |
            docker info
            set +o pipefail
            if [ -f /tmp/cache/docker.tar.gz ]; then
              wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
              sudo apt-get update && sudo apt-get -y install pigz
              pigz -d --stdout /tmp/cache/docker.tar.gz | docker load
              docker images
            fi
      - run:
          name: Remove any config file present in ds-sample/code and create ds-sample/test
          no_output_timeout: 8h
          command: |
            # Get version, update files.
            #THISVERSION=v$( python /home/circleci/src/connectomemapper3/get_version.py )
            #echo "THISVERSION : ${THISVERSION}"
            ls -la  /tmp/data/ds-sample/code

            # Remove existing config files in ds-sample (Make sure we are using the ones stored in the repo)
            rm -f /tmp/data/ds-sample/code/*.ini

            # Create the test folder to store list of test output files
            mkdir -p /tmp/data/ds-sample/test

            # Create the dataset dedicated to this job and copy data into it
            echo "Create test-dedicated dataset at: /tmp/data/${CIRCLE_JOB}/ds-sample"
            mkdir -p /tmp/data/${CIRCLE_JOB}/ds-sample
            cp -R /tmp/data/ds-sample/* /tmp/data/${CIRCLE_JOB}/ds-sample
      - run:
          name: Run anatomical and diffusion pipelines on ds-sample (test 1 - Lausanne2018 + FSL FLIRT + Dipy SHORE + MRtrix SD_STREAM tracking + MRtrix SIFT tractogram filtering)
          no_output_timeout: 8h
          command: |
            # Execute BIDS App
            docker run -it --rm \
                --entrypoint /app/run_coverage_cmp3.sh \
                -v /tmp/data/${CIRCLE_JOB}/ds-sample:/bids_dir \
                -v /tmp/data/${CIRCLE_JOB}/ds-sample/derivatives:/output_dir \
                -v /home/circleci/src/connectomemapper3/.circleci/tests/configuration_files:/config \
                sebastientourbier/connectomemapper3 \
                /bids_dir /output_dir participant --participant_label 01 --session_label 01 \
                --anat_pipeline_config /config/ref_anatomical_config_1.ini \
                --dwi_pipeline_config /config/ref_diffusion_config_1.ini \
                --fs_license /bids_dir/code/license.txt \
                --coverage

            # Rename partial coverage
            mv /tmp/data/${CIRCLE_JOB}/ds-sample/code/coverage.xml /tmp/data/ds-sample/test/test-01_coverage.xml

            # Rename execution log
            mv /tmp/data/${CIRCLE_JOB}/ds-sample/code/log.txt /tmp/data/ds-sample/test/test-01_log.txt
      - run:
          name: Checking outputs of Connectome Mapper run (test 1)
          command: |
            # Get all files in derivatives except the _*.json interface hash generated by nipype (find) /
            # Remove the full path of the derivatives (sed) / sort the files and write it to a text file
            sudo find /tmp/data/${CIRCLE_JOB}/ds-sample/derivatives -path */figures -prune -o -not -name "_*.json" -type f -print | sed s+/tmp/data/${CIRCLE_JOB}/ds-sample/derivatives/++ | sort > /tmp/data/ds-sample/test/test-01_outputs.out
            # diff /home/circleci/src/connectomemapper3/.circleci/tests/expected_outputs/ds-sample_test-01_outputs.txt /tmp/data/ds-sample/test/test-01_outputs.out
            # exit $?
      - run:
          name: Run anatomical and diffusion pipelines on ds-sample (test 2 - Lausanne2018 + ANTs SyN + Dipy SHORE + MRtrix ACT iFOV2 tracking)
          no_output_timeout: 8h
          command: |
            # Execute BIDS App
            docker run -it --rm \
                --entrypoint /app/run_coverage_cmp3.sh \
                -v /tmp/data/${CIRCLE_JOB}/ds-sample:/bids_dir \
                -v /tmp/data/${CIRCLE_JOB}/ds-sample/derivatives:/output_dir \
                -v /home/circleci/src/connectomemapper3/.circleci/tests/configuration_files:/config \
                sebastientourbier/connectomemapper3 \
                /bids_dir /output_dir participant --participant_label 01 --session_label 01 \
                --anat_pipeline_config /config/ref_anatomical_config_1.ini \
                --dwi_pipeline_config /config/ref_diffusion_config_2.ini \
                --fs_license /bids_dir/code/license.txt \
                --coverage

            # Rename partial coverage
            mv /tmp/data/${CIRCLE_JOB}/ds-sample/code/coverage.xml /tmp/data/ds-sample/test/test-02_coverage.xml

            # Rename execution log
            mv /tmp/data/${CIRCLE_JOB}/ds-sample/code/log.txt /tmp/data/ds-sample/test/test-02_log.txt
      - run:
          name: Checking outputs of Connectome Mapper run (test 2)
          command: |
            # Get all files in derivatives except the _*.json interface hash generated by nipype (find) /
            # Remove the full path of the derivatives (sed) / sort the files and write it to a text file
            sudo find /tmp/data/${CIRCLE_JOB}/ds-sample/derivatives -path */figures -prune -o -not -name "_*.json" -type f -print | sed s+/tmp/data/${CIRCLE_JOB}/ds-sample/derivatives/++ | sort > /tmp/data/ds-sample/test/test-02_outputs.out
            # diff /home/circleci/src/connectomemapper3/.circleci/tests/expected_outputs/ds-sample_test-02_outputs.txt /tmp/data/ds-sample/test/test-02_outputs.out
            # exit $?
      - persist_to_workspace:
          root: /tmp
          paths:
            - data/ds-sample/test
      - store_artifacts:
          path: /tmp/data/ds-sample/test
      - store_artifacts:
          path: /tmp/data/test_docker_dsi_mrtrix/ds-sample/code
      - store_artifacts:
          path: /tmp/data/test_docker_dsi_mrtrix/ds-sample/derivatives/cmp
      - store_artifacts:
          path: /tmp/data/test_docker_dsi_mrtrix/ds-sample/derivatives/nipype

  test_docker_dsi_dipy:
    machine:
      # Ubuntu 16.04, docker 18.09.3, docker-compose 1.23.1
      image: ubuntu-1604:201903-01

    working_directory: /tmp/data
    environment:
      - FS_LICENSE: /tmp/data/${CIRCLE_JOB}/ds-sample/code/license.txt
    steps:
      - checkout:
          path: /home/circleci/src/connectomemapper3
      - run:
          name: Check whether test_docker_dsi_dipy should be skipped
          command: |
            cd /home/circleci/src/connectomemapper3
            if [[ "$( git log --format=oneline -n 1 $CIRCLE_SHA1 | grep -i -E '\[skip[ _]?test_docker_dsi_dipy\]' )" != "" ]]; then
              echo "Skipping test_docker_dsi_dipy job"
              circleci step halt
            fi
      - attach_workspace:
          at: /tmp
      - run:
          name: Load Docker image layer cache
          no_output_timeout: 30m
          command: |
            docker info
            set +o pipefail
            if [ -f /tmp/cache/docker.tar.gz ]; then
              wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
              sudo apt-get update && sudo apt-get -y install pigz
              pigz -d --stdout /tmp/cache/docker.tar.gz | docker load
              docker images
            fi
      - run:
          name: Remove any config file present in ds-sample/code and create ds-sample/test
          no_output_timeout: 8h
          command: |
            # Get version, update files.
            #THISVERSION=v$( python /home/circleci/src/connectomemapper3/get_version.py )
            #echo "THISVERSION : ${THISVERSION}"
            ls -la  /tmp/data/ds-sample/code

            # Remove existing config files in ds-sample (Make sure we are using the ones stored in the repo)
            rm -f /tmp/data/ds-sample/code/*.ini

            # Create the test folder to store list of test output files
            mkdir -p /tmp/data/ds-sample/test

            # Create the dataset dedicated to this job and copy data into it
            echo "Create test-dedicated dataset at: /tmp/data/${CIRCLE_JOB}/ds-sample"
            mkdir -p /tmp/data/${CIRCLE_JOB}/ds-sample
            cp -R /tmp/data/ds-sample/* /tmp/data/${CIRCLE_JOB}/ds-sample
      - run:
          name: Run anatomical and diffusion pipelines on ds-sample (test 3 - Dipy SHORE + Deterministic tracking)
          no_output_timeout: 8h
          command: |
            # Execute BIDS App
            docker run -it --rm \
                --entrypoint /app/run_coverage_cmp3.sh \
                -v /tmp/data/${CIRCLE_JOB}/ds-sample:/bids_dir \
                -v /tmp/data/${CIRCLE_JOB}/ds-sample/derivatives:/output_dir \
                -v /home/circleci/src/connectomemapper3/.circleci/tests/configuration_files:/config \
                sebastientourbier/connectomemapper3 \
                /bids_dir /output_dir participant --participant_label 01 --session_label 01 \
                --anat_pipeline_config /config/ref_anatomical_config_1.ini \
                --dwi_pipeline_config /config/ref_diffusion_config_3.ini \
                --fs_license /bids_dir/code/license.txt \
                --coverage

            # Rename partial coverage
            mv /tmp/data/${CIRCLE_JOB}/ds-sample/code/coverage.xml /tmp/data/ds-sample/test/test-03_coverage.xml

            # Rename execution log
            mv /tmp/data/${CIRCLE_JOB}/ds-sample/code/log.txt /tmp/data/ds-sample/test/test-03_log.txt
      - run:
          name: Checking outputs of Connectome Mapper run (test 3)
          command: |
            # Get all files in derivatives except the _*.json interface hash generated by nipype (find) /
            # Remove the full path of the derivatives (sed) / sort the files and write it to a text file
            sudo find /tmp/data/${CIRCLE_JOB}/ds-sample/derivatives -path */figures -prune -o -not -name "_*.json" -type f -print | sed s+/tmp/data/${CIRCLE_JOB}/ds-sample/derivatives/++ | sort > /tmp/data/ds-sample/test/test-03_outputs.out
            # diff /home/circleci/src/connectomemapper3/.circleci/tests/expected_outputs/ds-sample_test-03_outputs.txt /tmp/data/ds-sample/test/test-03_outputs.out
            # exit $?
      - run:
          name: Run anatomical and diffusion pipelines on ds-sample (test 4 - Dipy SHORE + PFT tracking)
          no_output_timeout: 8h
          command: |
            # Execute BIDS App
            docker run -it --rm \
                --entrypoint /app/run_coverage_cmp3.sh \
                -v /tmp/data/${CIRCLE_JOB}/ds-sample:/bids_dir \
                -v /tmp/data/${CIRCLE_JOB}/ds-sample/derivatives:/output_dir \
                -v /home/circleci/src/connectomemapper3/.circleci/tests/configuration_files:/config \
                sebastientourbier/connectomemapper3 \
                /bids_dir /output_dir participant --participant_label 01 --session_label 01 \
                --anat_pipeline_config /config/ref_anatomical_config_1.ini \
                --dwi_pipeline_config /config/ref_diffusion_config_4.ini \
                --fs_license /bids_dir/code/license.txt \
                --coverage

            # Rename partial coverage
            mv /tmp/data/${CIRCLE_JOB}/ds-sample/code/coverage.xml /tmp/data/ds-sample/test/test-04_coverage.xml

            # Rename execution log
            mv /tmp/data/${CIRCLE_JOB}/ds-sample/code/log.txt /tmp/data/ds-sample/test/test-04_log.txt
      - run:
          name: Checking outputs of Connectome Mapper run (test 4)
          command: |
            # Get all files in derivatives except the _*.json interface hash generated by nipype (find) /
            # Remove the full path of the derivatives (sed) / sort the files and write it to a text file
            sudo find /tmp/data/${CIRCLE_JOB}/ds-sample/derivatives -path */figures -prune -o -not -name "_*.json" -type f -print | sed s+/tmp/data/${CIRCLE_JOB}/ds-sample/derivatives/++ | sort > /tmp/data/ds-sample/test/test-04_outputs.out
            # diff /home/circleci/src/connectomemapper3/.circleci/tests/expected_outputs/ds-sample_test-04_outputs.txt /tmp/data/ds-sample/test/test-04_outputs.out
            # exit $?
      - persist_to_workspace:
          root: /tmp
          paths:
            - data/ds-sample/test
      - store_artifacts:
          path: /tmp/data/ds-sample/test
      - store_artifacts:
          path: /tmp/data/test_docker_dsi_dipy/ds-sample/code
      - store_artifacts:
          path: /tmp/data/test_docker_dsi_dipy/ds-sample/derivatives/cmp
      - store_artifacts:
          path: /tmp/data/test_docker_dsi_dipy/ds-sample/derivatives/nipype

  test_docker_parcellation:
    machine:
      # Ubuntu 16.04, docker 18.09.3, docker-compose 1.23.1
      image: ubuntu-1604:201903-01

    working_directory: /tmp/data
    environment:
      - FS_LICENSE: /tmp/data/${CIRCLE_JOB}/ds-sample/code/license.txt
    steps:
      - checkout:
          path: /home/circleci/src/connectomemapper3
      - run:
          name: Check whether test_docker_parcellation should be skipped
          command: |
            cd /home/circleci/src/connectomemapper3
            if [[ "$( git log --format=oneline -n 1 $CIRCLE_SHA1 | grep -i -E '\[skip[ _]?test_docker_parcellation\]' )" != "" ]]; then
              echo "Skipping test_docker_parcellation job"
              circleci step halt
            fi
      - attach_workspace:
          at: /tmp
      - run:
          name: Load Docker image layer cache
          no_output_timeout: 30m
          command: |
            docker info
            set +o pipefail
            if [ -f /tmp/cache/docker.tar.gz ]; then
              wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
              sudo apt-get update && sudo apt-get -y install pigz
              pigz -d --stdout /tmp/cache/docker.tar.gz | docker load
              docker images
            fi
      - run:
          name: Remove any config file present in ds-sample/code and create ds-sample/test
          no_output_timeout: 1h
          command: |
            # Get version, update files.
            #THISVERSION=v$( python /home/circleci/src/connectomemapper3/get_version.py )
            #echo "THISVERSION : ${THISVERSION}"
            ls -la  /tmp/data/ds-sample/code

            # Remove existing config files in ds-sample (Make sure we are using the ones stored in the repo)
            rm -f /tmp/data/ds-sample/code/*.ini

            # Create the test folder to store list of test output files
            mkdir -p /tmp/data/ds-sample/test

            # Create the dataset dedicated to this job and copy data into it
            echo "Create test-dedicated dataset at: /tmp/data/${CIRCLE_JOB}/ds-sample"
            mkdir -p /tmp/data/${CIRCLE_JOB}/ds-sample
            cp -R /tmp/data/ds-sample/* /tmp/data/${CIRCLE_JOB}/ds-sample
      - run:
          name: Run anatomical pipeline on ds-sample (test 5 - NativeFreesurfer)
          no_output_timeout: 5h
          command: |
            # Execute BIDS App
            docker run -it --rm \
                --entrypoint /app/run_coverage_cmp3.sh \
                -v /tmp/data/${CIRCLE_JOB}/ds-sample:/bids_dir \
                -v /tmp/data/${CIRCLE_JOB}/ds-sample/derivatives:/output_dir \
                -v /home/circleci/src/connectomemapper3/.circleci/tests/configuration_files:/config \
                sebastientourbier/connectomemapper3 \
                /bids_dir /output_dir participant --participant_label 01 --session_label 01 \
                --anat_pipeline_config /config/ref_anatomical_config_2.ini \
                --fs_license /bids_dir/code/license.txt \
                --coverage

            # Rename partial coverage
            mv /tmp/data/${CIRCLE_JOB}/ds-sample/code/coverage.xml /tmp/data/ds-sample/test/test-05_coverage.xml

            # Rename execution log
            mv /tmp/data/${CIRCLE_JOB}/ds-sample/code/log.txt /tmp/data/ds-sample/test/test-05_log.txt
      - run:
          name: Checking outputs of Connectome Mapper run (test 5)
          command: |
            # Get all files in derivatives except the _*.json interface hash generated by nipype (find) /
            # Remove the full path of the derivatives (sed) / sort the files and write it to a text file
            sudo find /tmp/data/${CIRCLE_JOB}/ds-sample/derivatives -path */figures -prune -o -not -name "_*.json" -type f -print | sed s+/tmp/data/${CIRCLE_JOB}/ds-sample/derivatives/++ | sort > /tmp/data/ds-sample/test/test-05_outputs.out
            # diff /home/circleci/src/connectomemapper3/.circleci/tests/expected_outputs/ds-sample_test-05_outputs.txt /tmp/data/ds-sample/test/test-05_outputs.out
            # exit $?
      - run:
          name: Run anatomical pipeline on ds-sample (test 6 - Lausanne 2008)
          no_output_timeout: 5h
          command: |
            # Execute BIDS App
            docker run -it --rm \
                --entrypoint /app/run_coverage_cmp3.sh \
                -v /tmp/data/${CIRCLE_JOB}/ds-sample:/bids_dir \
                -v /tmp/data/${CIRCLE_JOB}/ds-sample/derivatives:/output_dir \
                -v /home/circleci/src/connectomemapper3/.circleci/tests/configuration_files:/config \
                sebastientourbier/connectomemapper3 \
                /bids_dir /output_dir participant --participant_label 01 --session_label 01 \
                --anat_pipeline_config /config/ref_anatomical_config_3.ini \
                --fs_license /bids_dir/code/license.txt \
                --coverage

            # Rename partial coverage
            mv /tmp/data/${CIRCLE_JOB}/ds-sample/code/coverage.xml /tmp/data/ds-sample/test/test-06_coverage.xml

            # Rename execution log
            mv /tmp/data/${CIRCLE_JOB}/ds-sample/code/log.txt /tmp/data/ds-sample/test/test-06_log.txt
      - run:
          name: Checking outputs of Connectome Mapper run (test 6)
          command: |
            # Get all files in derivatives except the _*.json interface hash generated by nipype (find) /
            # Remove the full path of the derivatives (sed) / sort the files and write it to a text file
            sudo find /tmp/data/${CIRCLE_JOB}/ds-sample/derivatives -path */figures -prune -o -not -name "_*.json" -type f -print | sed s+/tmp/data/${CIRCLE_JOB}/ds-sample/derivatives/++ | sort > /tmp/data/ds-sample/test/test-06_outputs.out
            # diff /home/circleci/src/connectomemapper3/.circleci/tests/expected_outputs/ds-sample_test-06_outputs.txt /tmp/data/ds-sample/test/test-06_outputs.out
            # exit $?
      - run:
          name: Clean working directory
          when: always
          command: |
            sudo chown $(id -un):$(id -gn) -R /tmp/data/${CIRCLE_JOB}/ds-sample
            find /tmp/data/ds-sample/derivatives -not -name "*.svg" -not -name "*.html" -not -name "*.rst" \
                -not -name "*.mat" -not -name "*.gpickle" -not -name "*.lta" -not -name "*.json" -not -name "*.txt" \
                -not -name "*.log" -not -name "*.pklz" -type f -delete
      - persist_to_workspace:
          root: /tmp
          paths:
            - data/ds-sample/test
      - store_artifacts:
          path: /tmp/data/ds-sample/test
      - store_artifacts:
          path: /tmp/data/test_docker_parcellation/ds-sample/code
      - store_artifacts:
          path: /tmp/data/test_docker_parcellation/ds-sample/derivatives/cmp
      - store_artifacts:
          path: /tmp/data/test_docker_parcellation/ds-sample/derivatives/nipype

  test_docker_fmri:
    machine:
      # Ubuntu 16.04, docker 18.09.3, docker-compose 1.23.1
      image: ubuntu-1604:201903-01

    working_directory: /tmp/data
    environment:
      - FS_LICENSE: /tmp/data/${CIRCLE_JOB}/ds-sample/code/license.txt
    steps:
      - checkout:
          path: /home/circleci/src/connectomemapper3
      - run:
          name: Check whether test_docker_fmri should be skipped
          command: |
            cd /home/circleci/src/connectomemapper3
            if [[ "$( git log --format=oneline -n 1 $CIRCLE_SHA1 | grep -i -E '\[skip[ _]?test_docker_fmri\]' )" != "" ]]; then
              echo "Skipping test_docker_fmri job"
              circleci step halt
            fi
      - attach_workspace:
          at: /tmp
      - run:
          name: Load Docker image layer cache
          no_output_timeout: 30m
          command: |
            docker info
            set +o pipefail
            if [ -f /tmp/cache/docker.tar.gz ]; then
              wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
              sudo apt-get update && sudo apt-get -y install pigz
              pigz -d --stdout /tmp/cache/docker.tar.gz | docker load
              docker images
            fi
      - run:
          name: Remove any config file present in ds-sample/code and create ds-sample/test
          no_output_timeout: 8h
          command: |
            # Get version, update files.
            #THISVERSION=v$( python /home/circleci/src/connectomemapper3/get_version.py )
            #echo "THISVERSION : ${THISVERSION}"
            ls -la  /tmp/data/ds-sample/code

            # Remove existing config files in ds-sample (Make sure we are using the ones stored in the repo)
            rm -f /tmp/data/ds-sample/code/*.ini

            # Create the test folder to store list of test output files
            mkdir -p /tmp/data/ds-sample/test

            # Create the dataset dedicated to this job and copy data into it
            echo "Create test-dedicated dataset at: /tmp/data/${CIRCLE_JOB}/ds-sample"
            mkdir -p /tmp/data/${CIRCLE_JOB}/ds-sample
            cp -R /tmp/data/ds-sample/* /tmp/data/${CIRCLE_JOB}/ds-sample
      - run:
          name: Run anatomical and fmri pipelines on ds-sample (test 7 - Lausanne2018 + BBRegister + fmri)
          no_output_timeout: 8h
          command: |
            # Execute BIDS App
            docker run -it --rm \
                --entrypoint /app/run_coverage_cmp3.sh \
                -v /tmp/data/${CIRCLE_JOB}/ds-sample:/bids_dir \
                -v /tmp/data/${CIRCLE_JOB}/ds-sample/derivatives:/output_dir \
                -v /home/circleci/src/connectomemapper3/.circleci/tests/configuration_files:/config \
                sebastientourbier/connectomemapper3 \
                /bids_dir /output_dir participant --participant_label 01 --session_label 01 \
                --anat_pipeline_config /config/ref_anatomical_config_1.ini \
                --func_pipeline_config /config/ref_fMRI_config_1.ini \
                --fs_license /bids_dir/code/license.txt \
                --coverage

            # Rename partial coverage
            mv /tmp/data/${CIRCLE_JOB}/ds-sample/code/coverage.xml /tmp/data/ds-sample/test/test-07_coverage.xml

            # Rename execution log
            mv /tmp/data/${CIRCLE_JOB}/ds-sample/code/log.txt /tmp/data/ds-sample/test/test-07_log.txt
      - run:
          name: Checking outputs of Connectome Mapper run (test 7)
          command: |
            # Get all files in derivatives except the _*.json interface hash generated by nipype (find) /
            # Remove the full path of the derivatives (sed) / sort the files and write it to a text file
            sudo find /tmp/data/${CIRCLE_JOB}/ds-sample/derivatives -path */figures -prune -o -not -name "_*.json" -type f -print | sed s+/tmp/data/${CIRCLE_JOB}/ds-sample/derivatives/++ | sort > /tmp/data/ds-sample/test/test-07_outputs.out
            # diff /home/circleci/src/connectomemapper3/.circleci/tests/expected_outputs/ds-sample_test-07_outputs.txt /tmp/data/ds-sample/test/test-07_outputs.out
            # exit $?
      - run:
          name: Run anatomical and fmri pipelines on ds-sample (test 8 - Lausanne2018 + FSL FLIRT + All nuisance regression + linear detrending + scrubbing)
          no_output_timeout: 8h
          command: |
            # Execute BIDS App
            docker run -it --rm \
            --entrypoint /app/run_coverage_cmp3.sh \
            -v /tmp/data/${CIRCLE_JOB}/ds-sample:/bids_dir \
            -v /tmp/data/${CIRCLE_JOB}/ds-sample/derivatives:/output_dir \
            -v /home/circleci/src/connectomemapper3/.circleci/tests/configuration_files:/config \
            sebastientourbier/connectomemapper3 \
            /bids_dir /output_dir participant --participant_label 01 --session_label 01 \
            --anat_pipeline_config /config/ref_anatomical_config_1.ini \
            --func_pipeline_config /config/ref_fMRI_config_2.ini \
            --fs_license /bids_dir/code/license.txt \
            --coverage

            # Rename partial coverage
            mv /tmp/data/${CIRCLE_JOB}/ds-sample/code/coverage.xml /tmp/data/ds-sample/test/test-08_coverage.xml

            # Rename execution log
            mv /tmp/data/${CIRCLE_JOB}/ds-sample/code/log.txt /tmp/data/ds-sample/test/test-08_log.txt
      - run:
          name: Checking outputs of Connectome Mapper run (test 8)
          command: |
            # Get all files in derivatives except the _*.json interface hash generated by nipype (find) /
            # Remove the full path of the derivatives (sed) / sort the files and write it to a text file
            sudo find /tmp/data/${CIRCLE_JOB}/ds-sample/derivatives -path */figures -prune -o -not -name "_*.json" -type f -print | sed s+/tmp/data/${CIRCLE_JOB}/ds-sample/derivatives/++ | sort > /tmp/data/ds-sample/test/test-08_outputs.out
            # diff /home/circleci/src/connectomemapper3/.circleci/tests/expected_outputs/ds-sample_test-08_outputs.txt /tmp/data/ds-sample/test/test-08_outputs.out
            # exit $?
      - persist_to_workspace:
          root: /tmp
          paths:
            - data/ds-sample/test
      - store_artifacts:
          path: /tmp/data/ds-sample/test
      - store_artifacts:
          path: /tmp/data/test_docker_fmri/ds-sample/code
      - store_artifacts:
          path: /tmp/data/test_docker_fmri/ds-sample/derivatives/cmp
      - store_artifacts:
          path: /tmp/data/test_docker_fmri/ds-sample/derivatives/nipype

  codacy_coverage_report:
    docker:
      - image: 'circleci/openjdk:8-jdk'
    working_directory: /tmp/data/ds-sample/code
    steps:
      - attach_workspace:
          at: /tmp
      - run:
          name: Run Codacy Coverage Reporter to convert and upload the reports to Codacy
          command: |
            export CODACY_REPORTER_VERSION=latest
            export CODACY_PROJECT_TOKEN=${CODACY_PROJECT_TOKEN}
            # Handles partial reports and send the final report to Codacy
            bash <(curl -Ls https://coverage.codacy.com/get.sh) report \
                -l Python -r /tmp/data/ds-sample/test/test-01_coverage.xml --partial &&\
            bash <(curl -Ls https://coverage.codacy.com/get.sh) report \
                -l Python -r /tmp/data/ds-sample/test/test-02_coverage.xml --partial &&\
            bash <(curl -Ls https://coverage.codacy.com/get.sh) report \
                -l Python -r /tmp/data/ds-sample/test/test-03_coverage.xml --partial &&\
            bash <(curl -Ls https://coverage.codacy.com/get.sh) report \
                -l Python -r /tmp/data/ds-sample/test/test-04_coverage.xml --partial &&\
            bash <(curl -Ls https://coverage.codacy.com/get.sh) report \
                -l Python -r /tmp/data/ds-sample/test/test-05_coverage.xml --partial &&\
            bash <(curl -Ls https://coverage.codacy.com/get.sh) report \
                -l Python -r /tmp/data/ds-sample/test/test-06_coverage.xml --partial &&\
            bash <(curl -Ls https://coverage.codacy.com/get.sh) report \
                -l Python -r /tmp/data/ds-sample/test/test-07_coverage.xml --partial &&\
            bash <(curl -Ls https://coverage.codacy.com/get.sh) report \
                -l Python -r /tmp/data/ds-sample/test/test-08_coverage.xml --partial &&\
            bash <(curl -Ls https://coverage.codacy.com/get.sh) final

  send_codecov_report:
    docker:
      - image: 'circleci/openjdk:8-jdk'
    working_directory: /tmp/data/ds-sample/code
    steps:
      - attach_workspace:
          at: /tmp
      - codecov/upload:
          file: /tmp/data/ds-sample/test/test-01_coverage.xml
      - codecov/upload:
          file: /tmp/data/ds-sample/test/test-02_coverage.xml
      - codecov/upload:
          file: /tmp/data/ds-sample/test/test-03_coverage.xml
      - codecov/upload:
          file: /tmp/data/ds-sample/test/test-04_coverage.xml
      - codecov/upload:
          file: /tmp/data/ds-sample/test/test-05_coverage.xml
      - codecov/upload:
          file: /tmp/data/ds-sample/test/test-06_coverage.xml
      - codecov/upload:
          file: /tmp/data/ds-sample/test/test-07_coverage.xml
      - codecov/upload:
          file: /tmp/data/ds-sample/test/test-08_coverage.xml

  test_singularity_parcellation:
    machine:
      # Ubuntu 16.04, docker 18.09.3, docker-compose 1.23.1
      image: ubuntu-1604:201903-01
    working_directory: /tmp/data
    environment:
      - FS_LICENSE: /tmp/data/${CIRCLE_JOB}/ds-sample/code/license.txt
    steps:
      - checkout:
          path: /home/circleci/src/connectomemapper3
      - run:
          name: Check whether test_singularity_parcellation should be skipped
          command: |
            cd /home/circleci/src/connectomemapper3
            if [[ "$( git log --format=oneline -n 1 $CIRCLE_SHA1 | grep -i -E '\[skip[ _]?test_singularity_parcellation\]' )" != "" ]]; then
              echo "Skipping test_singularity_parcellation job"
              circleci step halt
            fi
      - attach_workspace:
          at: /tmp
      - singularity/install-go:
          go-version: '1.13'
      - singularity/debian-install-3:
          singularity-version: 3.7.3
      - run:
          name: Remove any config file present in ds-sample/code and create ds-sample/test
          no_output_timeout: 1h
          command: |
            # Get version, update files.
            #THISVERSION=v$( python /home/circleci/src/connectomemapper3/get_version.py )
            #echo "THISVERSION : ${THISVERSION}"
            ls -la  /tmp/data/ds-sample/code

            # Remove existing config files in ds-sample (Make sure we are using the ones stored in the repo)
            rm -f /tmp/data/ds-sample/code/*.ini

            # Create the test folder to store list of test output files
            mkdir -p /tmp/data/ds-sample/test

            # Create the dataset dedicated to this job and copy data into it
            echo "Create test-dedicated dataset at: /tmp/data/${CIRCLE_JOB}/ds-sample"
            mkdir -p /tmp/data/${CIRCLE_JOB}/ds-sample
            cp -R /tmp/data/ds-sample/* /tmp/data/${CIRCLE_JOB}/ds-sample
      - run:
          name: Run anatomical pipeline on ds-sample (test 5 bis - NativeFreesurfer)
          no_output_timeout: 5h
          command: |
            # Execute BIDS App
            singularity run --containall \
                --bind /tmp/data/${CIRCLE_JOB}/ds-sample:/bids_dir \
                --bind /tmp/data/${CIRCLE_JOB}/ds-sample/derivatives:/output_dir \
                --bind /home/circleci/src/connectomemapper3/.circleci/tests/configuration_files:/config \
                /tmp/cache/connectomemapper3.simg \
                /bids_dir /output_dir participant --participant_label 01 --session_label 01 \
                --anat_pipeline_config /config/ref_anatomical_config_2.ini \
                --fs_license /bids_dir/code/license.txt
      - run:
          name: Checking outputs of Connectome Mapper run (test 5)
          command: |
            # Get all files in derivatives except the _*.json interface hash generated by nipype (find) /
            # Remove the full path of the derivatives (sed) / sort the files and write it to a text file
            sudo find /tmp/data/${CIRCLE_JOB}/ds-sample/derivatives -path */figures -prune -o -not -name "_*.json" -type f -print | sed s+/tmp/data/${CIRCLE_JOB}/ds-sample/derivatives/++ | sort > /tmp/data/ds-sample/test/test-05-simg_outputs.out
            # diff /home/circleci/src/connectomemapper3/.circleci/tests/expected_outputs/ds-sample_test-05-simg_outputs.txt /tmp/data/ds-sample/test/test-05-simg_outputs.out
            # exit $?
      - run:
          name: Run anatomical pipeline on ds-sample (test 6 bis - Lausanne 2008)
          no_output_timeout: 5h
          command: |
            # Execute BIDS App
            singularity run --containall \
                --bind /tmp/data/${CIRCLE_JOB}/ds-sample:/bids_dir \
                --bind /tmp/data/${CIRCLE_JOB}/ds-sample/derivatives:/output_dir \
                --bind /home/circleci/src/connectomemapper3/.circleci/tests/configuration_files:/config \
                /tmp/cache/connectomemapper3.simg \
                /bids_dir /output_dir participant --participant_label 01 --session_label 01 \
                --anat_pipeline_config /config/ref_anatomical_config_3.ini \
                --fs_license /bids_dir/code/license.txt \
                --coverage
      - run:
          name: Checking outputs of Connectome Mapper run (test 6)
          command: |
            # Get all files in derivatives except the _*.json interface hash generated by nipype (find) /
            # Remove the full path of the derivatives (sed) / sort the files and write it to a text file
            sudo find /tmp/data/${CIRCLE_JOB}/ds-sample/derivatives -path */figures -prune -o -not -name "_*.json" -type f -print | sed s+/tmp/data/${CIRCLE_JOB}/ds-sample/derivatives/++ | sort > /tmp/data/ds-sample/test/test-06-simg_outputs.out
            # diff /home/circleci/src/connectomemapper3/.circleci/tests/expected_outputs/ds-sample_test-06-simg_outputs.txt /tmp/data/ds-sample/test/test-06-simg_outputs.out
            # exit $?
      - run:
          name: Clean working directory
          when: always
          command: |
            sudo chown $(id -un):$(id -gn) -R /tmp/data/${CIRCLE_JOB}/ds-sample
            find /tmp/data/ds-sample/derivatives -not -name "*.svg" -not -name "*.html" -not -name "*.rst" \
                -not -name "*.mat" -not -name "*.gpickle" -not -name "*.lta" -not -name "*.json" -not -name "*.txt" \
                -not -name "*.log" -not -name "*.pklz" -type f -delete
      - persist_to_workspace:
          root: /tmp
          paths:
            - data/ds-sample/test
      - store_artifacts:
          path: /tmp/data/ds-sample/test
      - store_artifacts:
          path: /tmp/data/test_singularity_parcellation/ds-sample/code
      - store_artifacts:
          path: /tmp/data/test_singularity_parcellation/ds-sample/derivatives/cmp
      - store_artifacts:
          path: /tmp/data/test_singularity_parcellation/ds-sample/derivatives/nipype

  build_docs:
    machine:
      # Ubuntu 16.04, docker 18.09.3, docker-compose 1.23.1
      image: ubuntu-1604:201903-01
    working_directory: /home/circleci/out/docs
    steps:
      - checkout:
          path: /home/circleci/src/connectomemapper3
      - run:
          name: Check whether build should be skipped
          command: |
            cd /home/circleci/src/connectomemapper3
            if [[ "$( git log --format=oneline -n 1 $CIRCLE_SHA1 | grep -i -E '\[skip[ _]?docs\]' )" != "" ]]; then
              echo "Skipping documentation build job"
              circleci step halt
            fi

      - attach_workspace:
          at: /tmp
      - run:
          name: Load Docker image layer cache
          no_output_timeout: 30m
          command: |
            docker info
            set +o pipefail
            if [ -f /tmp/cache/docker.tar.gz ]; then
              wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
              sudo apt-get update && sudo apt-get -y install pigz
              pigz -d --stdout /tmp/cache/docker.tar.gz | docker load
              docker images
            fi
      - run:
          name: Build Connectome Mapper 3 documentation
          no_output_timeout: 2h
          command: |
            docker run -ti --rm=false -v $PWD:/_build_html \
              --entrypoint=sphinx-build sebastientourbier/connectomemapper3:latest \
              -T -E -b html -d _build/doctrees-readthedocs -W -D \
              language=en /root/src/connectomemapper3/docs/ /_build_html 2>&1 \
              | tee $PWD/builddocs.log
            cat $PWD/builddocs.log
            grep -qv "ERROR" $PWD/builddocs.log
      - store_artifacts:
          path: /home/circleci/out/docs

  deploy_docker_release:
    machine:
      # Ubuntu 14.04 with Docker 17.10.0-ce
      image: ubuntu-1604:201903-01
    working_directory: /tmp/src/connectomemapper3
    steps:
      - checkout:
          path: /home/circleci/src/connectomemapper3
      - attach_workspace:
          at: /tmp
      - run:
          name: Load Docker image layer cache
          no_output_timeout: 30m
          command: |
            docker info
            set +o pipefail
            if [ -f /tmp/cache/docker.tar.gz ]; then
              wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
              sudo apt-get update && sudo apt-get -y install pigz
              pigz -d --stdout /tmp/cache/docker.tar.gz | docker load
              docker images
            fi
      - run:
          name: Deploy release with version tag to Docker Hub
          no_output_timeout: 40m
          command: |
            # Get version, update files.
            THISVERSION=$( python /home/circleci/src/connectomemapper3/get_version.py )
            echo "THISVERSION : ${THISVERSION}"
            echo "CIRCLE_TAG : ${CIRCLE_TAG}"

            if [[ -n "$DOCKER_PASS" ]]; then
              docker login -u $DOCKER_USER -p $DOCKER_PASS
              if [[ -n "$CIRCLE_TAG" ]]; then
                docker tag sebastientourbier/connectomemapper3 sebastientourbier/connectomemapper-bidsapp:$CIRCLE_TAG
                docker push sebastientourbier/connectomemapper-bidsapp:$CIRCLE_TAG
              fi
            fi

  deploy_docker_latest:
    machine:
      # Ubuntu 14.04 with Docker 17.10.0-ce
      image: ubuntu-1604:201903-01
    working_directory: /tmp/src/connectomemapper3
    steps:
      - checkout:
          path: /home/circleci/src/connectomemapper3
      - attach_workspace:
          at: /tmp
      - run:
          name: Load Docker image layer cache
          no_output_timeout: 30m
          command: |
            docker info
            set +o pipefail
            if [ -f /tmp/cache/docker.tar.gz ]; then
              wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
              sudo apt-get update && sudo apt-get -y install pigz
              pigz -d --stdout /tmp/cache/docker.tar.gz | docker load
              docker images
            fi
      - run:
          name: Deploy latest master to Docker Hub
          no_output_timeout: 40m
          command: |
            # Get version, update files.
            THISVERSION=$( python /home/circleci/src/connectomemapper3/get_version.py )
            echo "THISVERSION : ${THISVERSION}"
            echo "CIRCLE_BRANCH : ${CIRCLE_BRANCH}"

            if [[ -n "$DOCKER_PASS" ]]; then
              docker login -u $DOCKER_USER -p $DOCKER_PASS
              docker tag sebastientourbier/connectomemapper3 sebastientourbier/connectomemapper-bidsapp:latest
              docker push sebastientourbier/connectomemapper-bidsapp:latest
            fi

  deploy_singularity_latest:
    machine:
      # Ubuntu 16.04, docker 18.09.3, docker-compose 1.23.1
      image: ubuntu-1604:201903-01
    working_directory: /tmp/src/connectomemapper3
    steps:
      - checkout:
          path: /home/circleci/src/connectomemapper3
      - run:
          name: "Check whether test should be skipped"
          command: |
            cd /home/circleci/src/connectomemapper3
            if [[ "$( git log --format=oneline -n 1 $CIRCLE_SHA1 | grep -i -E '\[skip[ _]?deploy_singularity]' )" != "" ]]; then
              echo "Skipping singularity deployment"
              circleci step halt
            fi
      - attach_workspace:
          at: /tmp
      - singularity/install-go:
          go-version: '1.13'
      - singularity/debian-install-3:
          singularity-version: 3.7.3
      - run:
          name: 'Write Sylabs.io TOKEN'
          command: |
            mkdir -p ~/.singularity
            touch ~/.singularity/sylabs-token
            echo "${SINGULARITY_TOKEN}" > ~/.singularity/sylabs-token
            cat ~/.singularity/sylabs-token
      - run:
          name: 'Deploy simg with latest tag to Sylabs.io'
          command: |
            singularity delete --arch=amd64 library://connectomicslab/default/connectomemapper-bidsapp:latest
            singularity push -U /tmp/cache/connectomemapper3.simg library://connectomicslab/default/connectomemapper-bidsapp:latest

  deploy_singularity_release:
    machine:
      # Ubuntu 16.04, docker 18.09.3, docker-compose 1.23.1
      image: ubuntu-1604:201903-01
    working_directory: /tmp/src/connectomemapper3
    steps:
      - checkout:
          path: /home/circleci/src/connectomemapper3
      - run:
          name: "Check whether test should be skipped"
          command: |
            cd /home/circleci/src/connectomemapper3
            if [[ "$( git log --format=oneline -n 1 $CIRCLE_SHA1 | grep -i -E '\[skip[ _]?deploy_singularity]' )" != "" ]]; then
              echo "Skipping singularity deployment"
              circleci step halt
            fi
      - attach_workspace:
          at: /tmp
      - singularity/install-go:
          go-version: '1.13'
      - singularity/debian-install-3:
          singularity-version: 3.7.3
      - run:
          name: 'Write Sylabs.io TOKEN'
          command: |
            mkdir -p ~/.singularity
            touch ~/.singularity/sylabs-token
            echo "${SINGULARITY_TOKEN}" > ~/.singularity/sylabs-token
            cat ~/.singularity/sylabs-token
      - run:
          name: 'Deploy simg with version tag to Sylabs.io'
          command: |
            # Get version, update files.
            # FIXME: cannot use python (might need to install extra package with apt-get)
            # THISVERSION="$( python /home/circleci/src/connectomemapper3/get_version.py )"
            # echo "THISVERSION : ${THISVERSION}"
            echo "CIRCLE_TAG : ${CIRCLE_TAG}"
            singularity push -U /tmp/cache/connectomemapper3.simg library://connectomicslab/default/connectomemapper-bidsapp:latest

workflows:
  version: 2.1
  build_test_cov_deploy:
    jobs:
      - test-python-install:
          version: "3.7"
          filters:
            tags:
              only: /.*/

      - build_docker:
          requires:
            - test-python-install
          filters:
            tags:
              only: /.*/

      - build_singularity:
          requires:
            - build_docker
          filters:
            tags:
              only: /.*/

      - get_data:
          filters:
            branches:
              ignore:
                - /docs?\/.*/
            tags:
              only: /.*/

      # - build_docs:
      #     requires:
      #       - build_docker
      #     filters:
      #       branches:
      #         ignore:
      #           - /ds-sample\/.*/
      #       tags:
      #         only: /.*/

      # - update_cache:
      #     requires:
      #       - build_docker
      #     filters:
      #       branches:
      #         ignore:
      #           - /docs?\/.*/
      #       tags:
      #         only: /.*/

      - test_docker_dsi_mrtrix:
          requires:
            - get_data
            # - update_cache
            - build_docker
          filters:
            branches:
              ignore:
                - /docs?\/.*/
            tags:
              only: /.*/

      - test_docker_dsi_dipy:
          requires:
            - get_data
            # - update_cache
            - build_docker
          filters:
            branches:
              ignore:
                - /docs?\/.*/
            tags:
              only: /.*/

      # JOB taking more than 5hours (CircleCI hard limit)
      - test_docker_parcellation:
          requires:
            - get_data
            # - update_cache
            - build_docker
            - build_singularity  # delay this job as we are limited to 4 concurrent jobs
          filters:
            branches:
              ignore:
                - /docs?\/.*/
            tags:
              only: /.*/

      - test_singularity_parcellation:
          requires:
            - get_data
            - build_singularity
          filters:
            branches:
              ignore:
                - /docs?\/.*/
            tags:
              only: /.*/

      - test_docker_fmri:
          requires:
            - get_data
            # - update_cache
            - build_docker
          filters:
            branches:
              ignore:
                - /docs?\/.*/
            tags:
              only: /.*/

      - codacy_coverage_report:
          requires:
            - test_singularity_parcellation
            - test_docker_dsi_mrtrix
            - test_docker_dsi_dipy
            - test_docker_parcellation
            - test_docker_fmri
          filters:
              branches:
                ignore:
                  - /docs?\/.*/
              tags:
                only: /.*/

      - send_codecov_report:
          requires:
            - test_singularity_parcellation
            - test_docker_dsi_mrtrix
            - test_docker_dsi_dipy
            - test_docker_parcellation
            - test_docker_fmri
          filters:
            branches:
              ignore:
                - /docs?\/.*/
            tags:
              only: /.*/

      - deploy_docker_release:
          requires:
            # - build_docs
            - test_docker_dsi_mrtrix
            - test_docker_dsi_dipy
            - test_docker_parcellation
            - test_docker_fmri
            - codacy_coverage_report
          filters:
            # ignore any commit on any branch by default
            branches:
              ignore: /.*/
              # only: master
            # only act on version tags
            tags:
              only: /^v.*/

      - deploy_docker_latest:
          requires:
            # - build_docs
            - test_docker_dsi_mrtrix
            - test_docker_dsi_dipy
            - test_docker_parcellation
            - test_docker_fmri
            - codacy_coverage_report
          filters:
            # ignore any commit on any branch by default
            branches:
              only: master

      - deploy_singularity_release:
          requires:
            # - build_docs
            - test_singularity_parcellation
            - test_docker_dsi_mrtrix
            - test_docker_dsi_dipy
            - test_docker_parcellation
            - test_docker_fmri
            - codacy_coverage_report
          filters:
            # ignore any commit on any branch by default
            branches:
              ignore: /.*/
              # only: master
            # only act on version tags
            tags:
              only: /^v.*/
