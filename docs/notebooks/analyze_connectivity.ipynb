{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from os import path as op\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graphs(output_dir,subjects,parcellation_scheme,weight):\n",
    "\n",
    "    print('Load graph for {} parcellation scheme '.format(parcellation_scheme))\n",
    "    \n",
    "    if parcellation_scheme == 'Lausanne2018':\n",
    "        bids_atlas_label = 'L2018'\n",
    "    elif parcellation_scheme == 'NativeFreesurfer':\n",
    "        bids_atlas_label = 'Desikan'\n",
    "        \n",
    "    multiscale_graphs = OrderedDict()\n",
    "\n",
    "    if parcellation_scheme == 'NativeFreesurfer':\n",
    "        \n",
    "        singlescale_graphs = OrderedDict()\n",
    "        \n",
    "        for subj in subjects:\n",
    "            print('> Process subject {}'.format(subj))\n",
    "            subj_dir = os.path.join(output_dir,subj)\n",
    "            subj_session_dirs = glob(op.join(subj_dir, \"ses-*\"))\n",
    "            subj_sessions = ['ses-{}'.format(subj_session_dir.split(\"-\")[-1]) for subj_session_dir in subj_session_dirs]\n",
    "\n",
    "            if len(subj_sessions) > 0: #Session structure\n",
    "                \n",
    "                for subj_session in subj_sessions:\n",
    "                    print('  Process session {} ()'.format(subj_session))\n",
    "                    conn_derivatives_dir = op.join(output_dir, subj, subj_session, 'connectivity')\n",
    "                    #Extract the connectivity graph \n",
    "                    connmat_fname = op.join(conn_derivatives_dir,'{}_{}_label-{}_conndata-snetwork_connectivity.gpickle'.format(subj,subj_session,bids_atlas_label))\n",
    "                    print('    - Load graph {}'.format(connmat_fname))\n",
    "                    G = nx.read_gpickle(connmat_fname)\n",
    "                    \n",
    "                    for u,v,d in G.edges(data=True):\n",
    "                        weight_val = d[weight]\n",
    "                        G.remove_edge(u,v)\n",
    "                        G.add_edge(u,v)\n",
    "                        G[u][v][weight] = weight_val\n",
    "                        \n",
    "                    fname = os.path.basename(connmat_fname)\n",
    "                    singlescale_graphs[fname] = G\n",
    "                    #Extract the connectivity matrix for a specific metric\n",
    "                    #connmat = nx.to_numpy_matrix(conngraph,weight=weight,dtype=np.float32)\n",
    "                singlescale_graphs[fname] = conngraph\n",
    "                    \n",
    "            else:\n",
    "                conn_derivatives_dir = op.join(output_dir, subj,'connectivity')\n",
    "                #Extract the connectivity graph \n",
    "                conngraph_fname = op.join(conn_derivatives_dir,'{}_label-{}_conndata-snetwork_connectivity.gpickle'.format(subj,bids_atlas_label))\n",
    "                print('    - Load graph {}'.format(connmat_fname))\n",
    "                G = nx.read_gpickle(connmat_fname)\n",
    "                    \n",
    "                for u,v,d in G.edges(data=True):\n",
    "                    weight_val = d[weight]\n",
    "                    G.remove_edge(u,v)\n",
    "                    G.add_edge(u,v)\n",
    "                    G[u][v][weight] = weight_val\n",
    "\n",
    "                fname = os.path.basename(connmat_fname)\n",
    "                singlescale_graphs[fname] = G\n",
    "                #Extract the connectivity matrix for a specific metric\n",
    "                #connmat = nx.to_numpy_matrix(conngraph,weight=weight,dtype=np.float32)\n",
    "        multiscale_graphs['scale1'] = singlescale_graphs\n",
    "                \n",
    "    else:\n",
    "        # For each parcellation scale\n",
    "        for scale in np.arange(1,6):\n",
    "            singlescale_graphs = OrderedDict()\n",
    "            for subj in subjects:\n",
    "                print('> Process subject {}'.format(subj))\n",
    "                subj_dir = os.path.join(output_dir,subj)\n",
    "                subj_session_dirs = glob(op.join(subj_dir, \"ses-*\"))\n",
    "                subj_sessions = ['ses-{}'.format(subj_session_dir.split(\"-\")[-1]) for subj_session_dir in subj_session_dirs]\n",
    "                if len(subj_sessions) > 0: #Session structure\n",
    "                    for subj_session in subj_sessions:\n",
    "                        print('  Process session {}'.format(subj_session))\n",
    "                        conn_derivatives_dir = op.join(output_dir, subj, subj_session, 'connectivity')\n",
    "                        #Extract the connectivity graph \n",
    "                        #self.subject+'_label-'+bids_atlas_label+'_desc-scale5_conndata-snetwork_connectivity'\n",
    "                        connmat_fname = op.join(conn_derivatives_dir,'{}_{}_label-{}_desc-scale{}_conndata-snetwork_connectivity.gpickle'.format(subj,subj_session,bids_atlas_label,scale))\n",
    "                        print('    - Load graph {}'.format(connmat_fname))\n",
    "                        G = nx.read_gpickle(connmat_fname)\n",
    "                    \n",
    "                        for u,v,d in G.edges(data=True):\n",
    "                            weight_val = d[weight]\n",
    "                            G.remove_edge(u,v)\n",
    "                            G.add_edge(u,v)\n",
    "                            G[u][v][weight] = weight_val\n",
    "\n",
    "                        fname = os.path.basename(connmat_fname)\n",
    "                        singlescale_graphs[fname] = G\n",
    "                        #Extract the connectivity matrix for a specific metric\n",
    "                        #connmat = nx.to_numpy_matrix(conngraph,weight=weight,dtype=np.float32)\n",
    "                else:\n",
    "                    conn_derivatives_dir = op.join(output_dir, subj,'connectivity')\n",
    "                    #Extract the connectivity graph \n",
    "                    connmat_fname = op.join(conn_derivatives_dir,'{}_label-{}_desc-scale{}_conndata-snetwork_connectivity.gpickle'.format(subj,bids_atlas_label,scale))\n",
    "                    print('    - Load graph {}'.format(connmat_fname))\n",
    "                    G = nx.read_gpickle(connmat_fname)\n",
    "                    \n",
    "                    for u,v,d in G.edges(data=True):\n",
    "                        weight_val = d[weight]\n",
    "                        G.remove_edge(u,v)\n",
    "                        G.add_edge(u,v)\n",
    "                        G[u][v][weight] = weight_val\n",
    "                        \n",
    "                    fname = os.path.basename(connmat_fname)\n",
    "                    singlescale_graphs[fname] = G\n",
    "                    #Extract the connectivity matrix for a specific metric\n",
    "                    #connmat = nx.to_numpy_matrix(conngraph,weight=weight,dtype=np.float32)\n",
    "            \n",
    "            multiscale_graphs['scale{}'.format(scale)] = singlescale_graphs\n",
    "\n",
    "    return multiscale_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load graph for Lausanne2018 parcellation scheme \n",
      "> Process subject sub-A001\n",
      "  Process session ses-20150203160809\n",
      "    - Load graph /Users/sebastientourbier/Desktop/DS-test/derivatives/cmp/sub-A001/ses-20150203160809/connectivity/sub-A001_ses-20150203160809_label-L2018_desc-scale1_conndata-snetwork_connectivity.gpickle\n",
      "  Process session ses-20150203160808\n",
      "    - Load graph /Users/sebastientourbier/Desktop/DS-test/derivatives/cmp/sub-A001/ses-20150203160808/connectivity/sub-A001_ses-20150203160808_label-L2018_desc-scale1_conndata-snetwork_connectivity.gpickle\n",
      "> Process subject sub-A002\n",
      "    - Load graph /Users/sebastientourbier/Desktop/DS-test/derivatives/cmp/sub-A002/connectivity/sub-A002_label-L2018_desc-scale1_conndata-snetwork_connectivity.gpickle\n",
      "> Process subject sub-A001\n",
      "  Process session ses-20150203160809\n",
      "    - Load graph /Users/sebastientourbier/Desktop/DS-test/derivatives/cmp/sub-A001/ses-20150203160809/connectivity/sub-A001_ses-20150203160809_label-L2018_desc-scale2_conndata-snetwork_connectivity.gpickle\n",
      "  Process session ses-20150203160808\n",
      "    - Load graph /Users/sebastientourbier/Desktop/DS-test/derivatives/cmp/sub-A001/ses-20150203160808/connectivity/sub-A001_ses-20150203160808_label-L2018_desc-scale2_conndata-snetwork_connectivity.gpickle\n",
      "> Process subject sub-A002\n",
      "    - Load graph /Users/sebastientourbier/Desktop/DS-test/derivatives/cmp/sub-A002/connectivity/sub-A002_label-L2018_desc-scale2_conndata-snetwork_connectivity.gpickle\n",
      "> Process subject sub-A001\n",
      "  Process session ses-20150203160809\n",
      "    - Load graph /Users/sebastientourbier/Desktop/DS-test/derivatives/cmp/sub-A001/ses-20150203160809/connectivity/sub-A001_ses-20150203160809_label-L2018_desc-scale3_conndata-snetwork_connectivity.gpickle\n",
      "  Process session ses-20150203160808\n",
      "    - Load graph /Users/sebastientourbier/Desktop/DS-test/derivatives/cmp/sub-A001/ses-20150203160808/connectivity/sub-A001_ses-20150203160808_label-L2018_desc-scale3_conndata-snetwork_connectivity.gpickle\n",
      "> Process subject sub-A002\n",
      "    - Load graph /Users/sebastientourbier/Desktop/DS-test/derivatives/cmp/sub-A002/connectivity/sub-A002_label-L2018_desc-scale3_conndata-snetwork_connectivity.gpickle\n",
      "> Process subject sub-A001\n",
      "  Process session ses-20150203160809\n",
      "    - Load graph /Users/sebastientourbier/Desktop/DS-test/derivatives/cmp/sub-A001/ses-20150203160809/connectivity/sub-A001_ses-20150203160809_label-L2018_desc-scale4_conndata-snetwork_connectivity.gpickle\n",
      "  Process session ses-20150203160808\n",
      "    - Load graph /Users/sebastientourbier/Desktop/DS-test/derivatives/cmp/sub-A001/ses-20150203160808/connectivity/sub-A001_ses-20150203160808_label-L2018_desc-scale4_conndata-snetwork_connectivity.gpickle\n",
      "> Process subject sub-A002\n",
      "    - Load graph /Users/sebastientourbier/Desktop/DS-test/derivatives/cmp/sub-A002/connectivity/sub-A002_label-L2018_desc-scale4_conndata-snetwork_connectivity.gpickle\n",
      "> Process subject sub-A001\n",
      "  Process session ses-20150203160809\n",
      "    - Load graph /Users/sebastientourbier/Desktop/DS-test/derivatives/cmp/sub-A001/ses-20150203160809/connectivity/sub-A001_ses-20150203160809_label-L2018_desc-scale5_conndata-snetwork_connectivity.gpickle\n",
      "  Process session ses-20150203160808\n",
      "    - Load graph /Users/sebastientourbier/Desktop/DS-test/derivatives/cmp/sub-A001/ses-20150203160808/connectivity/sub-A001_ses-20150203160808_label-L2018_desc-scale5_conndata-snetwork_connectivity.gpickle\n",
      "> Process subject sub-A002\n",
      "    - Load graph /Users/sebastientourbier/Desktop/DS-test/derivatives/cmp/sub-A002/connectivity/sub-A002_label-L2018_desc-scale5_conndata-snetwork_connectivity.gpickle\n"
     ]
    }
   ],
   "source": [
    "multiscale_graphs = load_graphs(output_dir='/Users/sebastientourbier/Desktop/DS-test/derivatives/cmp',\n",
    "            parcellation_scheme='Lausanne2018',\n",
    "            subjects=['sub-A001','sub-A002'],\n",
    "            weight='fiber_density')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check ordered dictionary of graphs for each scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale1 / list: OrderedDict([('sub-A001_ses-20150203160809_label-L2018_desc-scale1_conndata-snetwork_connectivity.gpickle', <networkx.classes.graph.Graph object at 0xa134097d0>), ('sub-A001_ses-20150203160808_label-L2018_desc-scale1_conndata-snetwork_connectivity.gpickle', <networkx.classes.graph.Graph object at 0xa13409b50>), ('sub-A002_label-L2018_desc-scale1_conndata-snetwork_connectivity.gpickle', <networkx.classes.graph.Graph object at 0x103e98fd0>)])\n",
      "scale2 / list: OrderedDict([('sub-A001_ses-20150203160809_label-L2018_desc-scale2_conndata-snetwork_connectivity.gpickle', <networkx.classes.graph.Graph object at 0xa13409e50>), ('sub-A001_ses-20150203160808_label-L2018_desc-scale2_conndata-snetwork_connectivity.gpickle', <networkx.classes.graph.Graph object at 0xa13409c50>), ('sub-A002_label-L2018_desc-scale2_conndata-snetwork_connectivity.gpickle', <networkx.classes.graph.Graph object at 0xa134095d0>)])\n",
      "scale3 / list: OrderedDict([('sub-A001_ses-20150203160809_label-L2018_desc-scale3_conndata-snetwork_connectivity.gpickle', <networkx.classes.graph.Graph object at 0xa13409750>), ('sub-A001_ses-20150203160808_label-L2018_desc-scale3_conndata-snetwork_connectivity.gpickle', <networkx.classes.graph.Graph object at 0xa13447390>), ('sub-A002_label-L2018_desc-scale3_conndata-snetwork_connectivity.gpickle', <networkx.classes.graph.Graph object at 0xa13409a90>)])\n",
      "scale4 / list: OrderedDict([('sub-A001_ses-20150203160809_label-L2018_desc-scale4_conndata-snetwork_connectivity.gpickle', <networkx.classes.graph.Graph object at 0xa13447190>), ('sub-A001_ses-20150203160808_label-L2018_desc-scale4_conndata-snetwork_connectivity.gpickle', <networkx.classes.graph.Graph object at 0xa13447950>), ('sub-A002_label-L2018_desc-scale4_conndata-snetwork_connectivity.gpickle', <networkx.classes.graph.Graph object at 0xa13447650>)])\n",
      "scale5 / list: OrderedDict([('sub-A001_ses-20150203160809_label-L2018_desc-scale5_conndata-snetwork_connectivity.gpickle', <networkx.classes.graph.Graph object at 0xa13447610>), ('sub-A001_ses-20150203160808_label-L2018_desc-scale5_conndata-snetwork_connectivity.gpickle', <networkx.classes.graph.Graph object at 0xa13447c10>), ('sub-A002_label-L2018_desc-scale5_conndata-snetwork_connectivity.gpickle', <networkx.classes.graph.Graph object at 0x103dec710>)])\n"
     ]
    }
   ],
   "source": [
    "for scale, graphs in multiscale_graphs.items():\n",
    "    print('{} / list: {}'.format(scale,graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Process scale1\n",
      "Computing: NNZ\n",
      "Sample Mean: 1183.00\n",
      "Computing: Max Local Statistic Sequence\n",
      "Subject Means: 0.14, 0.14, 0.14\n",
      "Computing: Clustering Coefficient Sequence\n",
      "Subject Means: 0.01, 0.01, 0.01\n",
      "Computing: Degree Sequence\n",
      "Subject Means: 0.01, 0.01, 0.01\n",
      "Computing: Edge Weight Sequence\n",
      "Subject Means: 0.00, 0.00, 0.00\n",
      "Computing: Eigen Value Sequence\n",
      "Subject Maxes: 1.21, 1.21, 1.21\n",
      "Computing: Betweenness Centrality Sequence\n",
      "Subject Means: 0.04, 0.04, 0.04\n",
      "Computing: Mean Connectome\n",
      "> Process scale2\n",
      "Computing: NNZ\n",
      "Sample Mean: 2129.00\n",
      "Computing: Max Local Statistic Sequence\n",
      "Subject Means: 0.16, 0.16, 0.16\n",
      "Computing: Clustering Coefficient Sequence\n",
      "Subject Means: 0.01, 0.01, 0.01\n",
      "Computing: Degree Sequence\n",
      "Subject Means: 0.01, 0.01, 0.01\n",
      "Computing: Edge Weight Sequence\n",
      "Subject Means: 0.00, 0.00, 0.00\n",
      "Computing: Eigen Value Sequence\n",
      "Subject Maxes: 1.21, 1.21, 1.21\n",
      "Computing: Betweenness Centrality Sequence\n",
      "Subject Means: 0.02, 0.02, 0.02\n",
      "Computing: Mean Connectome\n",
      "> Process scale3\n",
      "Computing: NNZ\n",
      "Sample Mean: 4026.00\n",
      "Computing: Max Local Statistic Sequence\n",
      "Subject Means: 0.15, 0.15, 0.15\n",
      "Computing: Clustering Coefficient Sequence\n",
      "Subject Means: 0.01, 0.01, 0.01\n",
      "Computing: Degree Sequence\n",
      "Subject Means: 0.01, 0.01, 0.01\n",
      "Computing: Edge Weight Sequence\n",
      "Subject Means: 0.00, 0.00, 0.00\n",
      "Computing: Eigen Value Sequence\n",
      "Subject Maxes: 1.21, 1.21, 1.21\n",
      "Computing: Betweenness Centrality Sequence\n",
      "Subject Means: 0.01, 0.01, 0.01\n",
      "Computing: Mean Connectome\n",
      "> Process scale4\n",
      "Computing: NNZ\n",
      "Sample Mean: 7406.00\n",
      "Computing: Max Local Statistic Sequence\n",
      "Subject Means: 0.13, 0.13, 0.13\n",
      "Computing: Clustering Coefficient Sequence\n",
      "Subject Means: 0.01, 0.01, 0.01\n",
      "Computing: Degree Sequence\n",
      "Subject Means: 0.01, 0.01, 0.01\n",
      "Computing: Edge Weight Sequence\n",
      "Subject Means: 0.00, 0.00, 0.00\n",
      "Computing: Eigen Value Sequence\n",
      "Subject Maxes: 1.24, 1.24, 1.24\n",
      "Computing: Betweenness Centrality Sequence\n",
      "Subject Means: 0.01, 0.01, 0.01\n",
      "Computing: Mean Connectome\n",
      "> Process scale5\n",
      "Computing: NNZ\n",
      "Sample Mean: 13995.00\n",
      "Computing: Max Local Statistic Sequence\n",
      "Subject Means: 0.10, 0.10, 0.10\n",
      "Computing: Clustering Coefficient Sequence\n",
      "Subject Means: 0.01, 0.01, 0.01\n",
      "Computing: Degree Sequence\n",
      "Subject Means: 0.01, 0.01, 0.01\n",
      "Computing: Edge Weight Sequence\n",
      "Subject Means: 0.00, 0.00, 0.00\n",
      "Computing: Eigen Value Sequence\n",
      "Subject Maxes: 1.29, 1.29, 1.29\n",
      "Computing: Betweenness Centrality Sequence\n"
     ]
    }
   ],
   "source": [
    "def scan_statistic(mygs, i):\n",
    "    \"\"\"\n",
    "    Computes scan statistic-i on a set of graphs\n",
    "    Required Parameters:\n",
    "        mygs:\n",
    "            - Dictionary of graphs\n",
    "        i:\n",
    "            - which scan statistic to compute\n",
    "    \"\"\"\n",
    "    ss = OrderedDict()\n",
    "    for key in list(mygs.keys()):\n",
    "        g = mygs[key]\n",
    "        tmp = np.array(())\n",
    "        for n in g.nodes():\n",
    "            sg = nx.ego_graph(g, n, radius=i)\n",
    "            \n",
    "            tmp = np.append(\n",
    "                tmp,\n",
    "                np.sum([sg.get_edge_data(e[0], e[1])[sg.get_edge_data(e[0], e[1]).keys()[0]] for e in sg.edges()]),\n",
    "            )\n",
    "        ss[key] = tmp\n",
    "    return ss\n",
    "\n",
    "def write(output_dir, metric, data, parcellation_scheme, scale=''):\n",
    "    \"\"\"\n",
    "    Write computed derivative to disk in a pickle file\n",
    "    Required parameters:\n",
    "        output_dir:\n",
    "            - Path to derivative save location\n",
    "        metric:\n",
    "            - The value that was calculated\n",
    "        data:\n",
    "            - The results of this calculation\n",
    "        parcellation scheme:\n",
    "            - Parcellation scheme used (L2018, L2008, Desikan)\n",
    "        scale:\n",
    "            - scale (only used if parcellation scheme is L2008 or L2018)\n",
    "    \"\"\"\n",
    "    import pickle\n",
    "    if parcellation_scheme == 'Desikan':\n",
    "        with open(op.join(output_dir, \"{}_{}.pkl\".format(parcellation_scheme,metric)), \"wb\") as of:\n",
    "            pickle.dump({metric: data}, of)\n",
    "    else:\n",
    "        with open(op.join(output_dir, \"{}_{}_{}.pkl\".format(parcellation_scheme,scale,metric)), \"wb\") as of:\n",
    "            pickle.dump({metric: data}, of)\n",
    "        \n",
    "\n",
    "def show_means(data):\n",
    "    print(\n",
    "        (\n",
    "            \"Subject Means: \"\n",
    "            + \", \".join([\"%.2f\" % np.mean(data[key]) for key in list(data.keys())])\n",
    "        )\n",
    "    )\n",
    "\n",
    "def compute_network_metrics(output_dir, multiscale_graphs, parcellation_scheme,weight):\n",
    "    for scale, graphs in multiscale_graphs.items():\n",
    "        print('> Process {}'.format(scale))     \n",
    "        nodes = nx.number_of_nodes(list(graphs.values())[0])\n",
    "        #  Number of non-zero edges (i.e. binary edge count)\n",
    "        print(\"Computing: NNZ\")\n",
    "        nnz = OrderedDict((subj, len(nx.edges(graphs[subj]))) for subj in graphs)\n",
    "        print((\"Sample Mean: %.2f\" % np.mean(list(nnz.values()))))\n",
    "        write(output_dir, \"number_non_zeros\", nnz, parcellation_scheme, scale)\n",
    "        \n",
    "        # Scan Statistic-1\n",
    "        print(\"Computing: Max Local Statistic Sequence\")\n",
    "        temp_ss1 = scan_statistic(graphs, 1)\n",
    "        ss1 = temp_ss1\n",
    "        write(output_dir, \"locality_statistic\", ss1, parcellation_scheme, scale)\n",
    "        show_means(temp_ss1)\n",
    "        \n",
    "        #   Clustering Coefficients\n",
    "        print(\"Computing: Clustering Coefficient Sequence\")\n",
    "        temp_cc = OrderedDict(\n",
    "            (subj, list(nx.clustering(graphs[subj], weight=weight).values())) for subj in graphs\n",
    "        )\n",
    "        ccoefs = temp_cc\n",
    "        write(output_dir, \"clustering_coefficients\", ccoefs, parcellation_scheme, scale)\n",
    "        show_means(temp_cc)\n",
    "        \n",
    "        #  Degree sequence\n",
    "        print(\"Computing: Degree Sequence\")\n",
    "        test = OrderedDict()\n",
    "        total_deg = OrderedDict(\n",
    "            (subj, np.array(list(dict(nx.degree(graphs[subj], weight=weight)).values())))\n",
    "            for subj in graphs\n",
    "        )\n",
    "        ipso_deg = OrderedDict()\n",
    "        contra_deg = OrderedDict()\n",
    "        for subj in graphs:  # TODO GK: remove forloop and use comprehension maybe?\n",
    "            g = graphs[subj]\n",
    "            N = len(list(g.nodes()))\n",
    "            LLnodes = list(g.nodes())[0 : N / 2]  # TODO GK: don't assume hemispheres\n",
    "            LL = g.subgraph(LLnodes)\n",
    "            LLdegs = [LL.degree(weight=weight)[n] for n in LLnodes]\n",
    "\n",
    "            RRnodes = list(g.nodes())[N / 2 : N]  # TODO GK: don't assume hemispheres\n",
    "            RR = g.subgraph(RRnodes)\n",
    "            RRdegs = [RR.degree(weight=weight)[n] for n in RRnodes]\n",
    "\n",
    "            LRnodes = g.nodes()\n",
    "            ipso_list = LLdegs + RRdegs\n",
    "            degs = [g.degree(weight=weight)[n] for n in LRnodes]\n",
    "            contra_deg[subj] = [a_i - b_i for a_i, b_i in zip(degs, ipso_list)]\n",
    "            ipso_deg[subj] = ipso_list\n",
    "        \n",
    "        # import pdb; pdb.set_trace()\n",
    "\n",
    "        deg = {\"total_deg\": total_deg, \"ipso_deg\": ipso_deg, \"contra_deg\": contra_deg}\n",
    "        write(output_dir, \"degree_distribution\", deg, parcellation_scheme, scale)\n",
    "        show_means(total_deg)\n",
    "        \n",
    "        #  Edge Weights\n",
    "        print(\"Computing: Edge Weight Sequence\")\n",
    "        temp_ew = OrderedDict(\n",
    "            (\n",
    "                s,\n",
    "                [\n",
    "                    graphs[s].get_edge_data(e[0], e[1])[graphs[s].get_edge_data(e[0], e[1]).keys()[0]]\n",
    "                    for e in graphs[s].edges()\n",
    "                ],\n",
    "            )\n",
    "            for s in graphs\n",
    "        )\n",
    "        ew = temp_ew\n",
    "        write(output_dir, \"edges_weight\", ew, parcellation_scheme, scale)\n",
    "        show_means(temp_ew)\n",
    "\n",
    "        # Eigen Values\n",
    "        print(\"Computing: Eigen Value Sequence\")\n",
    "        laplac = OrderedDict(\n",
    "            (subj, nx.normalized_laplacian_matrix(graphs[subj])) for subj in graphs\n",
    "        )\n",
    "        eigs = OrderedDict(\n",
    "            (subj, np.sort(np.linalg.eigvals(laplac[subj].A))[::-1]) for subj in graphs\n",
    "        )\n",
    "        write(output_dir, \"eigen_sequence\", eigs, parcellation_scheme, scale)\n",
    "        print(\n",
    "            (\n",
    "                \"Subject Maxes: \"\n",
    "                + \", \".join([\"%.2f\" % np.max(eigs[key]) for key in list(eigs.keys())])\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Betweenness Centrality\n",
    "        print(\"Computing: Betweenness Centrality Sequence\")\n",
    "        nxbc = nx.algorithms.betweenness_centrality\n",
    "        temp_bc = OrderedDict(\n",
    "            (subj, list(nxbc(graphs[subj], weight=weight).values())) for subj in graphs\n",
    "        )\n",
    "        centrality = temp_bc\n",
    "        write(output_dir, \"betweenness_centrality\", centrality, parcellation_scheme, scale)\n",
    "        show_means(temp_bc)\n",
    "\n",
    "        # Mean connectome\n",
    "        print(\"Computing: Mean Connectome\")\n",
    "        nxnp = nx.to_numpy_matrix\n",
    "        adj = OrderedDict(\n",
    "            (subj, nxnp(graph, nodelist=sorted(graph.nodes())))\n",
    "            for subj, graph in graphs.items()\n",
    "        )\n",
    "        mat = np.zeros(list(adj.values())[0].shape)\n",
    "        for subj in adj:\n",
    "            mat += adj[subj]\n",
    "        mat = mat / len(list(adj.keys()))\n",
    "        write(output_dir, \"mean_connectome\", mat, parcellation_scheme, scale)\n",
    "            \n",
    "    return mat\n",
    "# Need to create group folder\n",
    "mat = compute_network_metrics('/Users/sebastientourbier/Desktop/DS-test/derivatives/cmp/group', multiscale_graphs, 'L2018','fiber_density')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
